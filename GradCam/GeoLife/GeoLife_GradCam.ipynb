{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeoLife_GradCam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_8Wxok0g8eX",
        "outputId": "45a2d0d3-3333-428d-94d2-30eaef6ff777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import json\n",
        "\n",
        "path=\"/content/drive/My Drive/IFT6759/Ebird/Geolife\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n",
        "pthfile = r'checkpoint_33_10000.pth'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "class GradCAM(object):\n",
        "    def __init__(self, net, layer_name):\n",
        "        self.net = net\n",
        "        self.layer_name = layer_name\n",
        "        self.feature = None\n",
        "        self.gradient = None\n",
        "        self.net.eval()\n",
        "        self.handlers = []\n",
        "        self._register_hook()\n",
        "\n",
        "    def _get_features_hook(self, module, input, output):\n",
        "        self.feature = output\n",
        "        print(\"feature shape:{}\".format(output.size()))\n",
        "\n",
        "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
        "        \"\"\"\n",
        "        :param input_grad: tuple, input_grad[0]: None\n",
        "                                   input_grad[1]: weight\n",
        "                                   input_grad[2]: bias\n",
        "        :param output_grad:tuple,length = 1\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.gradient = output_grad[0]\n",
        "\n",
        "    def _register_hook(self):\n",
        "        for (name, module) in self.net.named_modules():\n",
        "            if name == self.layer_name:\n",
        "                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
        "                self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
        "\n",
        "    def remove_handlers(self):\n",
        "        for handle in self.handlers:\n",
        "            handle.remove()\n",
        "\n",
        "    def __call__(self, inputs, index):\n",
        "        \"\"\"\n",
        "        :param inputs: [1,3,H,W]\n",
        "        :param index: class id\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.net.zero_grad()\n",
        "        output = self.net(inputs)  # [1,num_classes]\n",
        "        if index is None:\n",
        "            index = np.argmax(output.cpu().data.numpy())\n",
        "        target = output[0][index]\n",
        "        target.backward()\n",
        "\n",
        "        gradient = self.gradient[0].cpu().data.numpy()  # [C,H,W]\n",
        "        weight = np.mean(gradient, axis=(1, 2))  # [C]\n",
        "\n",
        "        feature = self.feature[0].cpu().data.numpy()  # [C,H,W]\n",
        "\n",
        "        cam = feature * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
        "        cam = np.sum(cam, axis=0)  # [H,W]\n",
        "        cam = np.maximum(cam, 0)  # ReLU\n",
        "\n",
        "        # normalize\n",
        "        cam -= np.min(cam)\n",
        "        cam /= np.max(cam)\n",
        "        # resize to 224*224\n",
        "        cam = cv2.resize(cam, (224, 224))\n",
        "        return cam"
      ],
      "metadata": {
        "id": "Ievuh0tEhO5a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#still need to modify it\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class GuidedBackPropagation(object):\n",
        "\n",
        "    def __init__(self, net):\n",
        "        self.net = net\n",
        "        for (name, module) in self.net.named_modules():\n",
        "            if isinstance(module, nn.ReLU):\n",
        "                module.register_backward_hook(self.backward_hook)\n",
        "        self.net.eval()\n",
        "\n",
        "    @classmethod\n",
        "    def backward_hook(cls, module, grad_in, grad_out):\n",
        "        \"\"\"\n",
        "        :param module:\n",
        "        :param grad_in: tuple, length = 1\n",
        "        :param grad_out: tuple, length = 1\n",
        "        :return: tuple(new_grad_in,)\n",
        "        \"\"\"\n",
        "        return torch.clamp(grad_in[0], min=0.0),\n",
        "\n",
        "    def __call__(self, inputs, index=None):\n",
        "        \"\"\"\n",
        "        :param inputs: [1,3,H,W]\n",
        "        :param index: class_id\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.net.zero_grad()\n",
        "        output = self.net(inputs)  # [1,num_classes]\n",
        "        if index is None:\n",
        "            index = np.argmax(output.cpu().data.numpy())\n",
        "        target = output[0][index]\n",
        "\n",
        "        target.backward()\n",
        "\n",
        "        return inputs.grad[0]  # [3,H,W]"
      ],
      "metadata": {
        "id": "8-gJUQhThjlh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage import io\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "def get_net(net_name, weight_path=None):\n",
        "    \"\"\"\n",
        "    Get the model by network name\n",
        "    :param net_name: network name\n",
        "    :param weight_path: The path of trained weights\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    Geolife_net = torch.load(pthfile,map_location=torch.device('cpu'))\n",
        "    layers = list(Geolife_net[\"model_state_dict\"].keys())\n",
        "    for i in layers: \n",
        "      Geolife_net[\"model_state_dict\"][i.replace('backbone.', '')] =  Geolife_net[\"model_state_dict\"].pop(i)\n",
        "\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    model.conv1 = conv1\n",
        "    fc_features = model.fc.in_features \n",
        "    model.fc = torch.nn.Linear(fc_features, 31435)\n",
        "    model.load_state_dict(Geolife_net['model_state_dict'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_last_conv_name(net): \n",
        "    \"\"\"\n",
        "    Gets the name of the last convolutional layer of the network\n",
        "    :param net:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    layer_name = None\n",
        "    for name, m in net.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            layer_name = name\n",
        "    print(layer_name)\n",
        "    return layer_name\n",
        "\n",
        "\n",
        "def prepare_input(image): \n",
        "    image = image.copy().astype('float32')\n",
        "\n",
        "    # normalize\n",
        "    means = np.array([111.9393, 121.3099, 113.0863, 140.8277])\n",
        "    stds = np.array([51.5302,  45.5618,  41.4096,  54.2996])\n",
        "    image -= means\n",
        "    image /= stds\n",
        "\n",
        "    image = np.ascontiguousarray(np.transpose(image, (2, 0, 1)))  # channel first\n",
        "    image = image[np.newaxis, ...]  # adding batch dimension\n",
        "\n",
        "    return torch.tensor(image, requires_grad=True)\n",
        "\n",
        "\n",
        "def gen_cam(image, mask): \n",
        "    \"\"\"\n",
        "    Generated CAM figure\n",
        "    :param image: [H,W,C], original image\n",
        "    :param mask: [H,W],range 0~1\n",
        "    :return: tuple(cam,heatmap)\n",
        "    \"\"\"\n",
        "    # mask to heatmap\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    heatmap = heatmap[..., ::-1]  # gbr to rgb\n",
        "\n",
        "    # Merge heatMap to original image\n",
        "    print(heatmap.shape, image.shape)\n",
        "    cam = heatmap + np.float32(image[:,:,0:3])\n",
        "    return norm_image(cam), (heatmap * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def norm_image(image): \n",
        "    \"\"\"\n",
        "    normalize image\n",
        "    :param image: [H,W,C]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    image = image.copy()\n",
        "    image -= np.max(np.min(image), 0)\n",
        "    image /= np.max(image)\n",
        "    image *= 255.\n",
        "    return np.uint8(image)\n",
        "\n",
        "\n",
        "def gen_gb(grad):\n",
        "    \"\"\"\n",
        "    guided back propagation \n",
        "    :param grad: tensor,[3,H,W]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # normalize\n",
        "    grad = grad.data.numpy()\n",
        "    gb = np.transpose(grad, (1, 2, 0))\n",
        "    return gb\n",
        "\n",
        "def save_image(image_dicts, input_image_name, network, output_dir):\n",
        "    prefix = os.path.splitext(input_image_name)[0]\n",
        "    for key, image in image_dicts.items():\n",
        "        io.imsave(os.path.join(output_dir, '{}-{}-{}.jpg'.format(prefix, network, key)), image[:,:,0:3])\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # input\n",
        "    #img = io.imread(args.image_path)\n",
        "    arr = np.load(args.image_path)[:, :, 0:4]\n",
        "    img = np.float32(cv2.resize(arr, (224, 224), interpolation = cv2.INTER_AREA))\n",
        "    #alpha = \n",
        "    inputs = prepare_input(img)\n",
        "    # output \n",
        "    image_dict = {}\n",
        "    # net\n",
        "    net = get_net(args.network, args.weight_path)\n",
        "    # Grad-CAM\n",
        "    layer_name = get_last_conv_name(net) if args.layer_name is None else args.layer_name\n",
        "    grad_cam = GradCAM(net, layer_name)\n",
        "    mask = grad_cam(inputs, args.class_id)  # cam mask\n",
        "    image_dict['cam'], image_dict['heatmap'] = gen_cam(img, mask)\n",
        "    grad_cam.remove_handlers()\n",
        "\n",
        "\n",
        "    # GuidedBackPropagation\n",
        "    gbp = GuidedBackPropagation(net)\n",
        "    inputs.grad.zero_()  \n",
        "    grad = gbp(inputs)\n",
        "\n",
        "    gb = gen_gb(grad)\n",
        "    image_dict['gb'] = norm_image(gb)\n",
        "    # generate Guided Grad-CAM\n",
        "    cam_gb = gb * mask[..., np.newaxis]\n",
        "    image_dict['cam_gb'] = norm_image(cam_gb)\n",
        "\n",
        "    save_image(image_dict, os.path.basename(args.image_path), args.network, args.output_dir)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--network', type=str, default='resnet50',\n",
        "                        help='ImageNet classification network')\n",
        "    parser.add_argument('--image-path', type=str, default='./images/200.npy',\n",
        "                        help='input image path')\n",
        "    parser.add_argument('--weight-path', type=str, default='checkpoint_33_10000.pth',\n",
        "                        help='weight path of the model')\n",
        "    parser.add_argument('--layer-name', type=str, default=None,\n",
        "                        help='last convolutional layer name')\n",
        "    parser.add_argument('--class-id', type=int, default=None,\n",
        "                        help='class id')\n",
        "    parser.add_argument('--output-dir', type=str, default='results',\n",
        "                        help='output directory to save results')\n",
        "    arguments = parser.parse_args(args=[])\n",
        "    main(arguments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bkFq9ACh03y",
        "outputId": "9d23621a-3f30-4f8a-ee43-b93f3833639f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer4.2.conv3\n",
            "feature shape:torch.Size([1, 2048, 7, 7])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3) (224, 224, 4)\n"
          ]
        }
      ]
    }
  ]
}